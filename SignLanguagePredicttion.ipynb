{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skvideo.io import ffprobe, vread,vwrite,FFmpegWriter,FFmpegReader\n",
    "import imgaug.augmenters as iaa\n",
    "import re\n",
    "import mediapipe as mp\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D,MaxPool1D,GlobalMaxPool1D,TimeDistributed, BatchNormalization\n",
    "import datetime as dt\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Resizing The Videos (The Same Quality For All Data Videos): 256x256"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "PATH = '---'\n",
    "SAVE_PATH = '---'\n",
    "\n",
    "dataset_folder = os.listdir(PATH)\n",
    "\n",
    "print(\"--- Starting Resizing All Videos ---\\n\")\n",
    "for word_folder in dataset_folder:\n",
    "    for vid in os.listdir(os.path.join(PATH, word_folder)):\n",
    "        print(vid)\n",
    "        if not vid.endswith('.mp4'): ## if os.path.isdir(vid)\n",
    "            for v in os.listdir(os.path.join(PATH, word_folder, vid)):\n",
    "                video = vread(os.path.join(PATH, word_folder, vid, v))\n",
    "                resized_aug = iaa.Resize({\"height\": 256, \"width\": 256})\n",
    "                resized_vid = resized_aug.augment_images(video)\n",
    "                curr_vid_dir = os.path.join(SAVE_PATH, word_folder, vid, v)\n",
    "                curr_dir = os.path.join(SAVE_PATH, word_folder, vid)\n",
    "                isExist = os.path.isdir(curr_dir)\n",
    "                if not isExist:\n",
    "                    os.makedirs(curr_dir)\n",
    "                vwrite(curr_vid_dir, resized_vid)\n",
    "\n",
    "                print(curr_vid_dir, \"is resized successfully\")\n",
    "        else:\n",
    "            video = vread(os.path.join(PATH, word_folder, vid))\n",
    "            resized_aug = iaa.Resize({\"height\": 256, \"width\": 256})\n",
    "            resized_vid = resized_aug.augment_images(video)\n",
    "            curr_vid_dir = os.path.join(SAVE_PATH, word_folder, vid)\n",
    "            curr_dir = os.path.join(SAVE_PATH, word_folder)\n",
    "            isExist = os.path.isdir(curr_dir)\n",
    "            if not isExist:\n",
    "                os.mkdir(curr_dir)\n",
    "            vwrite(curr_vid_dir, resized_vid)\n",
    "\n",
    "            print(curr_vid_dir, \"is resized successfully\")\n",
    "\n",
    "print(\"*** Resizing Finished ***\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preprocessing Number of Frames To Be 30 Frames For All Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def isEven(number):\n",
    "    return number%2==0\n",
    "\n",
    "def fixVideo(frames,video_name,startFrames=0,endFrames=0,middleFrames=0):\n",
    "    folder_name=video_name.split('\\\\')[0]\n",
    "    file_name=video_name.split('\\\\')[1].split('.')[0]+\"_out.mp4\"\n",
    "    reader=FFmpegReader(video_name)\n",
    "    writer=FFmpegWriter(os.path.join(folder_name,file_name))\n",
    "    counter=0\n",
    "    reachMiddle=False\n",
    "    for frame in reader.nextFrame():\n",
    "        if startFrames!=0:\n",
    "            for i in range(2):\n",
    "                writer.writeFrame(frame)\n",
    "            startFrames-=1\n",
    "        elif middleFrames!=0 and reachMiddle:\n",
    "            for i in range(2):\n",
    "                writer.writeFrame(frame)\n",
    "            middleFrames-=1\n",
    "        elif endFrames!=0 and frames-counter==endFrames:\n",
    "            for i in range(2):\n",
    "                writer.writeFrame(frame)\n",
    "            endFrames-=1\n",
    "        else:\n",
    "            writer.writeFrame(frame)\n",
    "        counter+=1\n",
    "        if isEven(frames):\n",
    "            if frames/counter==2:\n",
    "                reachMiddle=True\n",
    "        if not isEven(frames):\n",
    "            if frames/(counter-0.5)==2:\n",
    "                reachMiddle=True\n",
    "    writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cd ---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Getting Videos' Metadata: To Get Number of Frames of Each Video"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data={\"Name\":[],\"Frames\":[]}\n",
    "\n",
    "for dir in os.listdir():\n",
    "    for file in os.listdir(os.path.join(os.curdir,dir)):\n",
    "        if file.endswith(\".mp4\"):\n",
    "            metadata = ffprobe(os.path.join(os.curdir,dir,file))\n",
    "            data[\"Name\"].append(os.path.join(dir,file))\n",
    "            data[\"Frames\"].append(metadata['video']['@nb_frames'])\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df[\"Frames\"]=df[\"Frames\"].astype(np.int32)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.to_csv(\"data.csv\",encoding=\"utf-8-sig\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.groupby('Label').count().sort_values(\"Video\")\n",
    "\n",
    "df = df.reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fixing Each Case Separately"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Increasing # Frames"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "variable = 26 ## Change The Number For Each Case\n",
    "\n",
    "for video in df[df[\"Frames\"] == variable][\"Name\"]:\n",
    "    fixVideo(variable,video,endFrames=1,startFrames=1,middleFrames=2)\n",
    "    os.remove(video) # Remove The Old Video As The Function Will Produce A New One"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Reducing # Frames"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[df[\"Frames\"] > 60]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "videos = df.loc[[3091,3112],\"Name\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Removing The Outliers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.drop(index=[1434,5568,5569],inplace=True)\n",
    "\n",
    "for video in df.loc[[386],\"Name\"]:\n",
    "    os.remove(video)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Applying Augmentation: To Increase The Number of Videos With Variation For Helping The Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "augs = [iaa.Rotate(5), iaa.Rotate(10), iaa.Rotate(15), iaa.Rotate(-5), iaa.Rotate(-10), iaa.Rotate(-15),\n",
    "        iaa.ShearX(5), iaa.ShearX(10), iaa.ShearX(-5), iaa.ShearX(-10),\n",
    "        iaa.ScaleY(1.1), iaa.ScaleY(0.9),\n",
    "        iaa.TranslateX(px=5), iaa.TranslateY(px=5),\n",
    "        iaa.Sequential([iaa.TranslateY(px=5),iaa.TranslateX(px=5)])]\n",
    "\n",
    "aug = iaa.Fliplr(1)\n",
    "\n",
    "for video in df[\"Video\"]:\n",
    "    video_file = vread(video)\n",
    "    output = aug.augment_images(video_file)\n",
    "    vwrite(f'{video.split(\".\")[0]}_filp.mp4',output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extracting The Features Using MediaPipe Framework"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Extracting All Landmarks of The Right & Left Hand & Only 4 Landmarks From The Pose (The Right Wrist & Elbow and The Left Wrist & Elbow)\n",
    "21 + 21 + 4 = 46 key points"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    la = np.array([[res.x, res.y, res.z] if res.visibility > 0.2 else [0,0,0] for res in np.array(results.pose_landmarks.landmark)[[13,15]]]) if results.pose_landmarks else np.zeros((2,3))\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]) if results.left_hand_landmarks else np.zeros((21,3))\n",
    "    ra = np.array([[res.x, res.y, res.z] if res.visibility > 0.2 else [0,0,0] for res in np.array(results.pose_landmarks.landmark)[[14,16]]]) if results.pose_landmarks else np.zeros((2,3))\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]) if results.right_hand_landmarks else np.zeros((21,3))\n",
    "    return np.concatenate([la ,lh ,ra , rh])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data={\"Name\":[],\"Label\":[]}\n",
    "\n",
    "for dir in os.listdir():\n",
    "    if os.path.isdir(os.path.join(os.curdir,dir)):\n",
    "        for video in os.listdir(dir):\n",
    "            if video.endswith(\".mp4\"):\n",
    "                data[\"Name\"].append(os.path.join(dir,video))\n",
    "                data[\"Label\"].append(dir)\n",
    "\n",
    "df=pd.DataFrame(data)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.001, min_tracking_confidence=0.001) as holistic:\n",
    "    for video in df[\"Name\"]:\n",
    "        if not os.path.isfile(video.split(\".\")[0]+\".npy\"):\n",
    "            reader = FFmpegReader(video)\n",
    "            results_arr = []\n",
    "\n",
    "            for frame in reader.nextFrame():\n",
    "                results = holistic.process(frame)\n",
    "                results_arr.append(extract_keypoints(results))\n",
    "\n",
    "            temp_arr = np.array(results_arr)\n",
    "            np.save(video.split(\".\")[0],temp_arr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = np.load(df[\"Name\"][0]).reshape((1,30,46,3))\n",
    "labels = [df[\"Label\"][0]]\n",
    "\n",
    "for data,label in list(zip(df[\"Name\"][1:],df[\"Label\"][1:])):\n",
    "    temp=np.load(data)\n",
    "    if np.all(temp==0):\n",
    "        continue\n",
    "    temp=temp.reshape((1,30,46,3))\n",
    "    X=np.concatenate([X,temp],axis=0)\n",
    "    labels.append(label)\n",
    "\n",
    "y = np.array(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Encoding The Labels/Classes (Words)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Saving The Features & Labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.save(\"Features\",X)\n",
    "np.save(\"Target\",y)\n",
    "joblib.dump(encoder,\"encoder.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Building The Model For Predicting The Signs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Splitting The Dataset To Training-set, Testing-set, and Validation-set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test   = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Building The Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model=  Sequential(name=\"CNNLSTM\")\n",
    "model.add(TimeDistributed(Conv1D(64, kernel_size=3, padding=\"same\", activation=\"relu\"), input_shape=X_train.shape[1:]))\n",
    "model.add(TimeDistributed(MaxPool1D()))\n",
    "model.add(TimeDistributed(Conv1D(96, kernel_size=3, padding=\"same\", activation=\"relu\")))\n",
    "model.add(TimeDistributed(MaxPool1D()))\n",
    "model.add(TimeDistributed(Conv1D(128, kernel_size=3, padding=\"same\", activation=\"relu\")))\n",
    "model.add(TimeDistributed(GlobalMaxPool1D()))\n",
    "model.add(LSTM(90, dropout=0.4, return_sequences=True))\n",
    "model.add(LSTM(45, dropout=0.4))\n",
    "model.add(Dense(100, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(50, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(np.unique(y).shape[0],activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=\"nadam\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def logPath():\n",
    "    return os.path.join(os.curdir,'logs',dt.datetime.now().strftime(\"run_%Y_%m_%d_%H_%M_%S\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=1000,\n",
    "          callbacks=[ModelCheckpoint(\"sadma2.h5\",monitor=\"val_accuracy\",save_best_only=True),\n",
    "                     EarlyStopping(monitor=\"val_accuracy\",patience=50,restore_best_weights=True),\n",
    "                     TensorBoard(log_dir=logPath())],\n",
    "          validation_data=(X_valid,y_valid))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading The Model, Features, and Labels To Evaluate Its Accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = np.load(\"Features.npy\")\n",
    "y = np.load(\"Target.npy\")\n",
    "encoder = joblib.load(\"encoder.pkl\")\n",
    "model = load_model(\"SignLanguageModel.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluating The Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.evaluate(X_train,y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.evaluate(X_valid,y_valid)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}